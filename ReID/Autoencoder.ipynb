{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Autoencoder.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwDCiOibbHzJ","executionInfo":{"status":"ok","timestamp":1627305708322,"user_tz":-420,"elapsed":1592,"user":{"displayName":"Vinh Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtR2GwoliQd_hETmVJah8f10EmkBUU-1tgdHbRWg=s64","userId":"10467210707890821402"}},"outputId":"cd94cca3-0f5f-4989-a004-6b0e50253153"},"source":["# 1. Import library\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Conv2D, Input, BatchNormalization, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from google.colab.patches import cv2_imshow \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","import cv2 as cv\n","import random\n","import time\n","import glob\n","\n","# 2. Define model and add noise function\n","def AEfunction(input_shape=(128,128,3)):\n","  \n","  # ENCODER\n","  X_input = Input(input_shape)\n","  \n","  x = Conv2D(128, (3, 3), activation='relu', padding='same')(X_input)\n","  x = BatchNormalization()(x)\n","  x = MaxPooling2D((2, 2), padding='same')(x)\n","  x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","  x = BatchNormalization()(x)\n","  x = MaxPooling2D((2, 2), padding='same')(x)\n","  x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","  x = BatchNormalization()(x)\n","  encoded = MaxPooling2D((2, 2), padding='same',name='encoder')(x)\n","\n","  # DECODER\n","  x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n","  x = BatchNormalization()(x)\n","  x = UpSampling2D((2, 2))(x)\n","  x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","  x = BatchNormalization()(x)\n","  x = UpSampling2D((2, 2))(x)\n","  x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","  x = BatchNormalization()(x)\n","  x = UpSampling2D((2, 2))(x)\n","  decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n","  \n","  model = Model(inputs = X_input, outputs = decoded, name='Autoencoder')\n","  \n","  return model\n","\n","def noisy(x):\n","  noise = np.random.normal(loc=0.0, scale=0.1, size=x.shape)\n","  x = x + noise\n","  x = x.clip(0.,1.)\n","  \n","  return x\n","\n","# 3. Load data and add noise\n","BATCH_SIZE = 128\n","datagen = ImageDataGenerator(rescale=1./255,\n","                             preprocessing_function=noisy)\n","X_train_noisy = datagen.flow_from_directory(\"/content/drive/MyDrive/Colab/ReID/Dataset/Train\",\n","                                      target_size=(128, 128),\n","                                      batch_size=BATCH_SIZE,\n","                                      class_mode='input')\n","X_test_noisy = datagen.flow_from_directory(\"/content/drive/MyDrive/Colab/ReID/Dataset/Test\",\n","                                           target_size=(128, 128),\n","                                           batch_size=BATCH_SIZE,\n","                                           class_mode='input')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 16522 images belonging to 1 classes.\n","Found 17661 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s17lXafbMcD","executionInfo":{"status":"ok","timestamp":1627309664478,"user_tz":-420,"elapsed":3954763,"user":{"displayName":"Vinh Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtR2GwoliQd_hETmVJah8f10EmkBUU-1tgdHbRWg=s64","userId":"10467210707890821402"}},"outputId":"3305891d-54bc-44c7-d9d6-9f07557b72df"},"source":["# 4. Define model\n","autoencoder = AEfunction(input_shape = (128, 128, 3))\n","\n","# 5. Compile model\n","autoencoder.compile(loss='mse',\n","              optimizer='adam')\n","\n","# 6. Train with data\n","\n","step_size_train = X_train_noisy.samples//BATCH_SIZE\n","step_size_valid = X_test_noisy.samples//BATCH_SIZE\n","\n","H = autoencoder.fit(X_train_noisy,\n","                    steps_per_epoch = step_size_train,\n","                    validation_data= X_test_noisy,\n","                    validation_steps = step_size_valid,\n","                    epochs = 3,\n","                    verbose= 1)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","129/129 [==============================] - 3597s 28s/step - loss: 0.0582 - val_loss: 0.0012\n","Epoch 2/3\n","129/129 [==============================] - 155s 1s/step - loss: 0.0100 - val_loss: 1.3036e-04\n","Epoch 3/3\n","129/129 [==============================] - 153s 1s/step - loss: 0.0067 - val_loss: 0.0015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4OwXD2fNyfO","executionInfo":{"status":"ok","timestamp":1627309740722,"user_tz":-420,"elapsed":320,"user":{"displayName":"Vinh Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtR2GwoliQd_hETmVJah8f10EmkBUU-1tgdHbRWg=s64","userId":"10467210707890821402"}},"outputId":"8ed2f45f-b4b2-4ccd-8656-2a2a093b3fcf"},"source":["autoencoder.save(\"/content/drive/MyDrive/Colab/ReID/autoencoder.h5\")\n","print(\"Saved\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Saved\n"],"name":"stdout"}]}]}